{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF postprocessing and evaluation for cancer detection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-processing\n",
    "from skimage import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np \n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, Dropout, concatenate, Reshape, Permute, Lambda, BatchNormalization\n",
    "from keras.activations import softmax\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, History\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
    "from keras_preprocessing import image\n",
    "\n",
    "import glob \n",
    "import cv2\n",
    "from scipy import misc\n",
    "import sys\n",
    "# import shutil\n",
    "\n",
    "from zipfile import ZipFile \n",
    "\n",
    "from keras.layers import Lambda\n",
    "from keras import backend as K\n",
    "\n",
    "import imageio\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import imageio\n",
    "\n",
    "import pandas as pd\n",
    "import six\n",
    "import csv\n",
    " \n",
    "\n",
    "ia.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask generator into one hot\n",
    "\n",
    "patch_size = 512\n",
    "batch_size = 16\n",
    "\n",
    "class MasksBatchGenerator(DirectoryIterator):\n",
    "    \n",
    "    def __init__(self,\n",
    "                directory, \n",
    "                image_data_generator,\n",
    "                target_size = (patch_size, patch_size),\n",
    "                num_channels = 1,\n",
    "                classes=None, \n",
    "                class_mode=None,\n",
    "                batch_size=batch_size, shuffle=True,\n",
    "                seed=None,\n",
    "                data_format=None,\n",
    "                save_to_dir=None,\n",
    "                save_prefix='',\n",
    "                save_format='png',\n",
    "                follow_links=False,\n",
    "                subset=None,\n",
    "                interpolation='nearest',\n",
    "                preprocessing_function= None):\n",
    "\n",
    "        super(MasksBatchGenerator,self).__init__(directory, \n",
    "                image_data_generator,                                              \n",
    "                target_size=target_size,                      \n",
    "                classes=classes,\n",
    "                class_mode=class_mode,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=shuffle,\n",
    "                seed=seed,\n",
    "                data_format=data_format,\n",
    "                save_to_dir=save_to_dir,\n",
    "                save_prefix=save_prefix,\n",
    "                save_format=save_format,\n",
    "                follow_links=follow_links,\n",
    "                subset=subset,\n",
    "                interpolation=interpolation)\n",
    "\n",
    "        self.image_shape = (target_size[0],target_size[1],num_channels)\n",
    "        self.preprocessing_function = preprocessing_function\n",
    "        \n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        \n",
    "        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype = K.floatx())\n",
    "        \n",
    "        for i, j in enumerate(index_array):\n",
    "            \n",
    "            fname = self.filenames[j]\n",
    "\n",
    "            img = cv2.cvtColor(cv2.imread(os.path.join(self.directory, fname)), cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            if self.preprocessing_function:\n",
    "                img = self.preprocessing_function(img)\n",
    "                \n",
    "            batch_x[i] = img\n",
    "            \n",
    "        return batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch generator\n",
    "\n",
    "class PatchBatchGenerator(DirectoryIterator):\n",
    "    \n",
    "    def __init__(self,\n",
    "                directory, \n",
    "                image_data_generator,\n",
    "                target_size = (patch_size, patch_size),\n",
    "                num_channels = 3,\n",
    "                color_mode = \"rgb\",\n",
    "                classes=None, \n",
    "                class_mode=None,\n",
    "                batch_size=batch_size, shuffle=True,\n",
    "                seed=None,\n",
    "                data_format=None,\n",
    "                save_to_dir=None,\n",
    "                save_prefix='',\n",
    "                save_format='jpg',\n",
    "                follow_links=False,\n",
    "                subset=None,\n",
    "                interpolation='nearest',\n",
    "                preprocessing_function= None):\n",
    "\n",
    "        super(PatchBatchGenerator,self).__init__(directory, \n",
    "                image_data_generator,\n",
    "                target_size=target_size,                      \n",
    "                classes=classes,\n",
    "                class_mode=class_mode,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=shuffle,\n",
    "                seed=seed,\n",
    "                data_format=data_format,\n",
    "                save_to_dir=save_to_dir,\n",
    "                save_prefix=save_prefix,\n",
    "                save_format=save_format,\n",
    "                follow_links=follow_links,\n",
    "                subset=subset,\n",
    "                interpolation=interpolation)\n",
    "\n",
    "        self.image_shape = (target_size[0],target_size[1],num_channels)\n",
    "        \n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        \n",
    "        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype = K.floatx())\n",
    "        \n",
    "        for i, j in enumerate(index_array):\n",
    "            \n",
    "            fname = self.filenames[j]\n",
    "            img = cv2.cvtColor(cv2.imread(os.path.join(self.directory, fname)), cv2.COLOR_BGR2RGB)        \n",
    "\n",
    "            batch_x[i] = img/255.0\n",
    "            \n",
    "        return batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask generator into one hot with statial augmentation\n",
    "\n",
    "\n",
    "class MasksBatchGeneratorAug(DirectoryIterator):\n",
    "    \n",
    "    def __init__(self,\n",
    "                directory, \n",
    "                image_data_generator,\n",
    "                target_size = (patch_size, patch_size),\n",
    "                num_channels = 1,\n",
    "                classes=None, \n",
    "                class_mode=None,\n",
    "                batch_size=batch_size, shuffle=True,\n",
    "                seed=None,\n",
    "                data_format=None,\n",
    "                save_to_dir=None,\n",
    "                save_prefix='',\n",
    "                save_format='png',\n",
    "                follow_links=False,\n",
    "                subset=None,\n",
    "                interpolation='nearest',\n",
    "                preprocessing_function= None,\n",
    "                preprocessing_function_space= None):\n",
    "\n",
    "        super(MasksBatchGeneratorAug,self).__init__(directory, \n",
    "                image_data_generator,\n",
    "                target_size=target_size,                      \n",
    "                classes=classes,\n",
    "                class_mode=class_mode,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=shuffle,\n",
    "                seed=seed,\n",
    "                data_format=data_format,\n",
    "                save_to_dir=save_to_dir,\n",
    "                save_prefix=save_prefix,\n",
    "                save_format=save_format,\n",
    "                follow_links=follow_links,\n",
    "                subset=subset,\n",
    "                interpolation=interpolation)\n",
    "\n",
    "        self.image_shape = (target_size[0],target_size[1],num_channels)\n",
    "        self.preprocessing_function_space = preprocessing_function_space\n",
    "        self.preprocessing_function = preprocessing_function\n",
    "        \n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        \n",
    "        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype = K.floatx())\n",
    "        \n",
    "        for i, j in enumerate(index_array):\n",
    "            \n",
    "            fname = self.filenames[j]\n",
    "            img = cv2.cvtColor(cv2.imread(os.path.join(self.directory, fname)), cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            if self.preprocessing_function_space:\n",
    "                img= self.preprocessing_function_space(img)\n",
    "            \n",
    "            if self.preprocessing_function:\n",
    "                img = self.preprocessing_function(img)\n",
    "                \n",
    "            batch_x[i] = img\n",
    "            \n",
    "        return batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch generator with statial augmentation\n",
    "\n",
    "\n",
    "class PatchBatchGeneratorAug(DirectoryIterator):\n",
    "    \n",
    "    def __init__(self,\n",
    "                directory, \n",
    "                image_data_generator,\n",
    "                target_size = (patch_size, patch_size),\n",
    "                num_channels = 3,\n",
    "                color_mode = \"rgb\",\n",
    "                classes=None, \n",
    "                class_mode=None,\n",
    "                batch_size=batch_size, shuffle=True,\n",
    "                seed=None,\n",
    "                data_format=None,\n",
    "                save_to_dir=None,\n",
    "                save_prefix='',\n",
    "                save_format='jpg',\n",
    "                follow_links=False,\n",
    "                subset=None,\n",
    "                interpolation='nearest',\n",
    "                preprocessing_function_space= None,\n",
    "                preprocessing_function= None):\n",
    "\n",
    "        super(PatchBatchGeneratorAug,self).__init__(directory, \n",
    "                image_data_generator,\n",
    "                target_size=target_size,                      \n",
    "                classes=classes,\n",
    "                class_mode=class_mode,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=shuffle,\n",
    "                seed=seed,\n",
    "                data_format=data_format,\n",
    "                save_to_dir=save_to_dir,\n",
    "                save_prefix=save_prefix,\n",
    "                save_format=save_format,\n",
    "                follow_links=follow_links,\n",
    "                subset=subset,\n",
    "                interpolation=interpolation)\n",
    "\n",
    "        self.image_shape = (target_size[0],target_size[1],num_channels)\n",
    "        self.preprocessing_function_space = preprocessing_function_space\n",
    "        \n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        \n",
    "        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype = K.floatx())\n",
    "        \n",
    "        for i, j in enumerate(index_array):\n",
    "            \n",
    "            fname = self.filenames[j]\n",
    "            img = cv2.cvtColor(cv2.imread(os.path.join(self.directory, fname)), cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            if self.preprocessing_function_space:\n",
    "                img= self.preprocessing_function_space(img)\n",
    "                \n",
    "            batch_x[i] = img/255.0\n",
    "            \n",
    "        return batch_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open image function\n",
    "\n",
    "def open_image(path):\n",
    "  newImage = Image.open(path)\n",
    "  return newImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0 is background, 1 is healthy, 2 is cancer\n",
    "def rgb_to_onehot_3cls(rgb_arr):\n",
    "    \n",
    "    color_dict = {0: [255, 255, 255], # white- background  bgr rgb GOOD\n",
    "              1: [255, 0, 255], # magenta - normal \n",
    "              2: [102, 102, 102], # gray- other GOOD\n",
    "              3: [50, 160, 50], # also something green- acinary tumour\n",
    "              4: [0, 255, 0], # green lime- lepidic tumour GOOD\n",
    "              5: [0, 0, 0], # black- solid tumour GOOD\n",
    "              6: [0, 75, 0], # - darker gree tumour\n",
    "              7: [130, 170, 130], # light green- micropapollary tumour \n",
    "                 }          \n",
    "             \n",
    "    num_classes = len(color_dict)-5\n",
    "    shape = rgb_arr.shape[:2]\n",
    "    arr = np.zeros( shape, dtype=np.int8 )\n",
    "    \n",
    "    for i, cls in color_dict.items():\n",
    "        \n",
    "        if i == 0:\n",
    "            \n",
    "            mask0 = rgb_arr[:, :, 0] == cls[0]\n",
    "            mask1 = rgb_arr[:, :, 1] == cls[1]\n",
    "            mask2 = rgb_arr[:, :, 2] == cls[2]\n",
    "            mask = np.logical_and(np.logical_and(mask0, mask1), mask2)\n",
    "            arr[mask] = i\n",
    "            \n",
    "        elif i == 1 or i == 2:\n",
    "            \n",
    "            mask0 = rgb_arr[:, :, 0] == cls[0]\n",
    "            mask1 = rgb_arr[:, :, 1] == cls[1]\n",
    "            mask2 = rgb_arr[:, :, 2] == cls[2]\n",
    "            mask = np.logical_and(np.logical_and(mask0, mask1), mask2)\n",
    "            arr[mask] = 1\n",
    "            \n",
    "        elif i == 3 or i == 4 or i == 5 or i == 6 or i == 7:\n",
    "            \n",
    "            mask0 = rgb_arr[:, :, 0] == cls[0]\n",
    "            mask1 = rgb_arr[:, :, 1] == cls[1]\n",
    "            mask2 = rgb_arr[:, :, 2] == cls[2]\n",
    "            mask = np.logical_and(np.logical_and(mask0, mask1), mask2)\n",
    "            arr[mask] = 2\n",
    "        \n",
    "    arr_vec=np.zeros((arr.shape[0], arr.shape[1], num_classes))\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        \n",
    "        mask = (arr == i)\n",
    "        arr_vec[:, :, i][mask] = 1 \n",
    "        \n",
    "    return arr_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRF_to_onehot(arr):\n",
    "    color_dict = {0: (1,   0, 0),       \n",
    "                  1: (0, 1, 0),   \n",
    "                  2: (0, 0,   1)}    \n",
    "    arr= np.squeeze(arr)\n",
    "    single_layer = arr\n",
    "    output = np.zeros((512,512,3))\n",
    "    for k in color_dict.keys():\n",
    "        output[single_layer==k] = color_dict[k]\n",
    "    return np.uint8(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_to_rgb_3cls(onehot):\n",
    "    \n",
    "    color_dict = {0: [255, 255, 255], # white- background  bgr rgb\n",
    "              1: [255, 0, 255], # non-cancer -blue\n",
    "              2: [0, 0, 0], # cancer -red\n",
    "                 }\n",
    "    single_layer = np.argmax(onehot, axis=-1)\n",
    "    output = np.zeros( onehot.shape[:2]+(3,) )\n",
    "    for k in color_dict.keys():\n",
    "        output[single_layer==k] = color_dict[k]\n",
    "    return np.uint8(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightness_augmentation(factor):\n",
    "    factor = factor\n",
    "    \n",
    "    def augment(img): \n",
    "\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV) #convert to hsv\n",
    "        hsv = np.array(hsv, dtype=np.float64)\n",
    "        hsv[:, :, 2] = hsv[:, :, 2] * (factor + np.random.uniform()) #scale channel V uniformly\n",
    "        hsv[:, :, 2][hsv[:, :, 2] > 255] = 255 #reset out of range values\n",
    "        rgb = cv2.cvtColor(np.array(hsv, dtype=np.uint8), cv2.COLOR_HSV2RGB)\n",
    "        \n",
    "        augment = rgb\n",
    "        return augment\n",
    "    \n",
    "    return augment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_categorical_crossentropy(weights):\n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        \n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurements\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "        \n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "\n",
    "    return fbeta_score(y_true, y_pred, beta=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics visualisation function\n",
    "\n",
    "def render_table(data, col_width = 3.0, row_height = 0.625, font_size = 14,\n",
    "                     header_color = '#F8F8FF', row_colors = ['w'], edge_color = '#D3D3D3',\n",
    "                     bbox = [0, 0, 1, 1], header_columns = 0,\n",
    "                     ax = None, **kwargs):\n",
    "    if ax is None:\n",
    "        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])\n",
    "        fig, ax = plt.subplots(figsize=size)\n",
    "        ax.axis('off')\n",
    "\n",
    "    mpl_table = ax.table(cellText = data.values, bbox = bbox, colLabels = data.columns, **kwargs)\n",
    "\n",
    "    mpl_table.auto_set_font_size(False)\n",
    "    mpl_table.set_fontsize(font_size)\n",
    "\n",
    "    for k, cell in six.iteritems(mpl_table._cells):\n",
    "        cell.set_edgecolor(edge_color)\n",
    "        if k[0] == 0 or k[1] < header_columns:\n",
    "            cell.set_text_props(weight = 'bold', color = '#000000')\n",
    "            cell.set_facecolor(header_color)\n",
    "        else:\n",
    "            cell.set_facecolor(row_colors[k[0]%len(row_colors)])\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model parameters (inputs)\n",
    "\n",
    "n_classes = 3\n",
    "patch_size = 512 #both height and width \n",
    "\n",
    "batch_size = 16\n",
    "n_epoch = 100\n",
    "\n",
    "learning_rate = 0.01\n",
    "patience = 100\n",
    "\n",
    "# type_loss_function = keras.losses.categorical_crossentropy\n",
    "class_weights = [1,1,2]\n",
    "type_loss_function = weighted_categorical_crossentropy(class_weights)\n",
    "# cells to be measured \n",
    "lim = 100\n",
    "\n",
    "# Data directory\n",
    "Test_path = \"/home/guest/DL/Teodora/Project/Test516\"\n",
    "Train_path = \"/home/guest/DL/Teodora/Project/Train516\"\n",
    "Val_path = \"/home/guest/DL/Teodora/Project/Validation516\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#U-net implementation\n",
    "\n",
    "inputs = Input((patch_size, patch_size, 3))\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', dilation_rate = 2)(inputs)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', dilation_rate = 2)(conv1)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "print(conv1.shape)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "\n",
    "print(conv2.shape)\n",
    "\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "print(conv3.shape)\n",
    "\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "print(conv4.shape)\n",
    "\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "print(conv5.shape)\n",
    "\n",
    "up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "\n",
    "up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "\n",
    "up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "\n",
    "up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "conv10 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "\n",
    "conv11 = Conv2D(n_classes, (1, 1), activation='linear')(conv10)\n",
    "print(conv10.shape)\n",
    "out=conv11\n",
    "out = Lambda(lambda x: softmax(x, axis = 3))(conv11)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[out])\n",
    "\n",
    "# keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)#learning rate optimisation\n",
    "model.compile(optimizer = 'adam', loss = type_loss_function, metrics=['accuracy', recall, precision, fmeasure])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_arg = dict()\n",
    "mask_arg = dict()\n",
    "# PatchBatchGenerator= ImageDataGenerator()\n",
    "\n",
    "test_patch_generator = PatchBatchGenerator(\n",
    "                                            directory= Test_path+'/Patches',\n",
    "                                            image_data_generator=ImageDataGenerator,\n",
    "                                            target_size=(patch_size, patch_size),\n",
    "                                            color_mode=\"rgb\",\n",
    "                                            batch_size=1,\n",
    "                                            class_mode=None,\n",
    "                                            shuffle=False,\n",
    "                                            seed=1)\n",
    "    \n",
    "    \n",
    "test_mask_generator = MasksBatchGenerator(\n",
    "                                            directory= Test_path+'/Masks',\n",
    "                                            image_data_generator=ImageDataGenerator,\n",
    "                                            target_size=(patch_size, patch_size),\n",
    "                                            num_channels=n_classes,\n",
    "                                            class_mode=None,\n",
    "                                            shuffle=False,\n",
    "                                            batch_size=1,\n",
    "                                            seed=1,\n",
    "                                            preprocessing_function =  rgb_to_onehot_3cls)   \n",
    "\n",
    "print('Test sets ready')\n",
    "\n",
    "test_only_patch_generator = test_patch_generator\n",
    "test_generator = zip(test_patch_generator, test_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_samples  = len([name for name in os.listdir(Test_path + '/Patches/Group1/')])\n",
    "print (n_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "exp='A'\n",
    "\n",
    "weights_path = os.path.dirname(os.path.realpath(\"Train\")) + '/Weights_data_cross'\n",
    "\n",
    "weights_file = weights_path + '/' + 'Weights.h5'\n",
    "\n",
    "#load weights\n",
    "model.load_weights(weights_file)\n",
    "\n",
    "\n",
    "print(\"Weights are loaded into model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = model.evaluate_generator(test_generator, n_test_samples, max_queue_size = 1)\n",
    "\n",
    "#Loss, accuracy, recall, precission, fmeasure\n",
    "print(test_scores) \n",
    "\n",
    "test_res = model.predict_generator(test_only_patch_generator, n_test_samples) # test set prediction map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pydensecrf.densecrf as dcrf\n",
    "\n",
    "from pydensecrf.utils import compute_unary, create_pairwise_bilateral, \\\n",
    "    create_pairwise_gaussian, softmax_to_unary, unary_from_softmax\n",
    "\n",
    "import skimage.io as io\n",
    "def load_patch(patch):\n",
    "    im = Image.open(patch )\n",
    "    im.load()\n",
    "    data = np.asarray( im, dtype=\"uint32\" )\n",
    "    return data\n",
    "\n",
    "n=878\n",
    "masks = [cv2.imread(file) for file in sorted(glob.glob(os.path.join(Test_path+'/Masks/Group1/', '*-labels.png')))]\n",
    "patches = [file for file in sorted(glob.glob(os.path.join(Test_path+'/Patches/Group1/', '*jpg')))]\n",
    "CRF_eval=[]\n",
    "CRF_res=[]\n",
    "\n",
    "# for i in range(0,n_test_samples):\n",
    "for i in range(n,n+1):  \n",
    "    image = load_patch(patches[i])\n",
    "    image = image/.255\n",
    "#     print(image.shape)\n",
    "\n",
    "    final_probabilities = test_res[i,:,:,:]\n",
    "#     print(len(final_probabilities[1,:,:])*len(final_probabilities[:,1,:]))\n",
    "    \n",
    "    processed_probabilities = final_probabilities.squeeze()\n",
    "\n",
    "    softmax = processed_probabilities.transpose((2, 0, 1))\n",
    "\n",
    "    # The input should be the negative of the logarithm of probability values\n",
    "    # Look up the definition of the softmax_to_unary for more information\n",
    "    unary = unary_from_softmax(softmax)\n",
    "\n",
    "    # The inputs should be C-continious -- we are using Cython wrapper\n",
    "    unary = np.ascontiguousarray(unary)\n",
    "\n",
    "    d = dcrf.DenseCRF2D(image.shape[0], image.shape[1], 3)\n",
    "    \n",
    "    d.setUnaryEnergy(unary)\n",
    "    d.addPairwiseGaussian(sxy=(5,5), compat=50, kernel=dcrf.FULL_KERNEL, normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "\n",
    "    # This adds the color-dependent term, i.e. features are (x,y,r,g,b).\n",
    "    d.addPairwiseBilateral(sxy=(5,5), srgb=(5,5,5), rgbim=cv2.cvtColor(cv2.imread(patches[i]), cv2.COLOR_BGR2RGB), compat=100, kernel=dcrf.DIAG_KERNEL, normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "\n",
    "    Q = d.inference(5)\n",
    "\n",
    "    res1 = np.argmax(Q, axis=0).reshape((image.shape[0], image.shape[1]))\n",
    "\n",
    "    CRF_eval.append(res1)\n",
    "    \n",
    "    #model segmentation\n",
    "    test_res_sample =  np.array(test_res[i,:,:,:])\n",
    "    most_prob = np.zeros(shape = [patch_size, patch_size, n_classes])\n",
    "\n",
    "    most_prob[:,:,0] = (np.array(test_res_sample[:,:,0] == np.fmax(np.fmax(test_res_sample[:,:,0], test_res_sample[:,:,1]),((test_res_sample[:,:,2]))),dtype = 'float32'))\n",
    "    most_prob[:,:,1] = (np.array(test_res_sample[:,:,1] == np.fmax(np.fmax(test_res_sample[:,:,0], test_res_sample[:,:,1]),((test_res_sample[:,:,2]))),dtype = 'float32'))\n",
    "    most_prob[:,:,2] = (np.array(test_res_sample[:,:,2] == np.fmax(np.fmax(test_res_sample[:,:,0], test_res_sample[:,:,1]),((test_res_sample[:,:,2]))),dtype = 'float32'))\n",
    "    \n",
    "    # Prediction annotations\n",
    "    \n",
    "    predicted_segmentation = onehot_to_rgb_3cls(most_prob)\n",
    "    pred1 = predicted_segmentation\n",
    "    \n",
    "    #CRF segmentation\n",
    "    res =np.array(CRF_to_onehot(res1))\n",
    "    \n",
    "    most_prob2 = np.zeros(shape = [patch_size, patch_size, n_classes])\n",
    "    most_prob3 = np.zeros(shape = [patch_size, patch_size, n_classes])\n",
    "    most_prob4 = np.zeros(shape = [patch_size, patch_size, n_classes])\n",
    "\n",
    "    most_prob2[:,:,0] = (np.array(res[:,:,0] == np.fmax(np.fmax(res[:,:,0], res[:,:,1]),((res[:,:,2]))),dtype = 'float32'))\n",
    "    most_prob2[:,:,1] = (np.array(res[:,:,1] == np.fmax(np.fmax(res[:,:,0], res[:,:,1]),((res[:,:,2]))),dtype = 'float32'))\n",
    "    most_prob2[:,:,2] = (np.array(res[:,:,2] == np.fmax(np.fmax(res[:,:,0], res[:,:,1]),((res[:,:,2]))),dtype = 'float32'))\n",
    "\n",
    "    most_prob3[:,:,0] = most_prob2[:,:,0]\n",
    "    most_prob3[:,:,1] = cv2.morphologyEx(most_prob2[:,:,1], cv2.MORPH_CLOSE, np.ones((5,5),np.uint8),iterations = 2)\n",
    "    most_prob3[:,:,2] = cv2.morphologyEx(most_prob2[:,:,2], cv2.MORPH_CLOSE, np.ones((5,5),np.uint8),iterations = 2)\n",
    "\n",
    "    \n",
    "    predicted_segmentation2 = onehot_to_rgb_3cls(most_prob2)\n",
    "    pred2 = predicted_segmentation2\n",
    "    \n",
    "    predicted_segmentation3 = onehot_to_rgb_3cls(most_prob3)\n",
    "    pred3 = predicted_segmentation3\n",
    "    \n",
    "    CRF_res.append(pred2)\n",
    "    \n",
    "#Extract contours\n",
    "    \n",
    "    magenta = np.array([255, 0, 255])\n",
    "    black = np.array([0, 0, 0])\n",
    "    white = np.array([255, 255, 255])\n",
    "    green = np.array([0, 255, 0])\n",
    "\n",
    "    only_magenta = cv2.inRange(pred2, magenta, magenta)\n",
    "    only_black = cv2.inRange(pred2, black, black)\n",
    "#     only_white = cv2.inRange(pred2, white, white)\n",
    "\n",
    "    c_m, _ = cv2.findContours(only_magenta, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    c_b, _  = cv2.findContours(only_black, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     c_w, _  = cv2.findContours(only_white, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    im_crf = np.copy(cv2.cvtColor(cv2.imread(patches[n]), cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    cv2.drawContours(im_crf, c_m, -1, (255, 0, 255), 5)\n",
    "    cv2.drawContours(im_crf, c_b, -1, (0, 0, 0), 3)\n",
    "#   cv2.drawContours(im, c_g, -1, (0, 255, 0), 3)\n",
    "    \n",
    "    magenta = np.array([255, 0, 255])\n",
    "    black = np.array([0, 0, 0])\n",
    "    white = np.array([255, 255, 255])\n",
    "    green = np.array([0, 255, 0])\n",
    "\n",
    "    only_magenta = cv2.inRange(pred1, magenta, magenta)\n",
    "    only_black = cv2.inRange(pred1, black, black)\n",
    "    only_white = cv2.inRange(pred1, white, white)\n",
    "\n",
    "    c_m, _ = cv2.findContours(only_magenta, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    c_b, _  = cv2.findContours(only_black, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     c_w, _  = cv2.findContours(only_white, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    im = np.copy(cv2.cvtColor(cv2.imread(patches[n]), cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    cv2.drawContours(im, c_m, -1, (255, 0, 255), 5)\n",
    "    cv2.drawContours(im, c_b, -1, (0, 0, 0), 3)\n",
    "    \n",
    "    \n",
    " # Ground truth annotations\n",
    "    mask_sample = cv2.cvtColor(masks[n], cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    gray = np.array([102, 102, 102])\n",
    "    green_acinar = np.array([50, 160, 50])\n",
    "    green_pap = np.array([0, 75, 0])\n",
    "    green_mpap = np.array([130, 170, 130])\n",
    "    \n",
    "    only_magenta_mask = cv2.inRange(mask_sample, magenta, magenta)\n",
    "    only_black_mask = cv2.inRange(mask_sample, black, black)\n",
    "    only_green_mask = cv2.inRange(mask_sample, green, green)\n",
    "    only_gray_mask = cv2.inRange(mask_sample, gray, gray)\n",
    "    only_green_ac_mask = cv2.inRange(mask_sample, green_acinar, green_acinar)\n",
    "    only_green_pa_mask = cv2.inRange(mask_sample, green_pap, green_pap)\n",
    "    only_green_mpa_mask = cv2.inRange(mask_sample, green_mpap, green_mpap)\n",
    "#     only_white = cv2.inRange(mask_sample, white, white)\n",
    "\n",
    "    c_m, _ = cv2.findContours(only_magenta_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    c_b, _  = cv2.findContours(only_black_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    c_green, _  = cv2.findContours(only_green_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    c_gray, _  = cv2.findContours(only_gray_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    c_green_pa, _  = cv2.findContours(only_green_pa_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    c_green_mpa, _  = cv2.findContours(only_green_mpa_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    c_green_ac, _  = cv2.findContours(only_green_ac_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     c_w, _  = cv2.findContours(only_white, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    im_mask = np.copy(cv2.cvtColor(cv2.imread(patches[n]), cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    cv2.drawContours(im_mask, c_m, -1, (255, 0, 255), 5)\n",
    "    cv2.drawContours(im_mask, c_gray, -1, (255, 0, 255), 5) \n",
    "    cv2.drawContours(im_mask, c_b, -1, (0, 0, 0), 3)\n",
    "    cv2.drawContours(im_mask, c_green, -1, (0, 0, 0), 3) \n",
    "    cv2.drawContours(im_mask, c_green_pa, -1, (0, 0, 0), 3)\n",
    "    cv2.drawContours(im_mask, c_green_mpa, -1, (0, 0, 0), 3)\n",
    "    cv2.drawContours(im_mask, c_green_ac, -1, (0, 0, 0), 3)\n",
    "   # cv2.drawContours(im, c_w, -1, (122, 122, 122), 1)\n",
    "    #cv2.imwrite(\"contours_blue.png\", im)\n",
    "    \n",
    "    (f, [ax00, ax0, ax1, ax2, ax4]) = plt.subplots(1, 5, figsize = (25, 5))\n",
    "    ax00.imshow(cv2.cvtColor(cv2.imread(patches[i]), cv2.COLOR_BGR2RGB))\n",
    "    ax0.imshow(pred1)\n",
    "    ax0.set_title('Segmentation with Unet') \n",
    "    ax1.imshow(pred2)\n",
    "    ax1.set_title('Segmentation with CRF post-processing')\n",
    "    ax2.imshow(pred3)\n",
    "    ax2.set_title('Segmentation with CRF post-processing and closing')\n",
    "#         ax3.imshow(pred4)\n",
    "#         ax3.set_title('Segmentation with CRF post-processing, closing and dilation')\n",
    "    ax4.imshow(cv2.cvtColor(masks[i], cv2.COLOR_BGR2RGB))\n",
    "    ax4.set_title('Ground-Truth Annotation')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    cv2.imwrite('figure.png',cv2.cvtColor(cv2.imread(patches[n]), cv2.COLOR_BGR2RGB))\n",
    "    cv2.imwrite('fig-pred-annot.png',im)\n",
    "    cv2.imwrite('fig-CRF-annot.png',im_crf)\n",
    "    cv2.imwrite('fig-gt-annot.png',im_mask)\n",
    "    cv2.imwrite('map-CRF-annot.png',pred2)\n",
    "    cv2.imwrite('map-pred-annot.png',pred1)\n",
    "    cv2.imwrite('map-gt-annot.png',cv2.cvtColor(masks[i], cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRF_res= np.array(CRF_res)\n",
    "\n",
    "# print(CRF_res[1])\n",
    "# CRF_res.shape\n",
    "# CRF_res[2,:,:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics per group of patchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "# Calculate precision and recall per tissue type\n",
    "epsi=0.00000001\n",
    "masks = [cv2.imread(file) for file in sorted(glob.glob(os.path.join(Test_path+'/Masks/Group1/', '*-labels.png')))]\n",
    "\n",
    "CRF_res= np.array(CRF_res)\n",
    "\n",
    "for i in range(0, len(masks)):\n",
    "    #b,g,r = cv2.split(masks[i])\n",
    "    masks[i] = (cv2.cvtColor(masks[i], cv2.COLOR_BGR2RGB))\n",
    "\n",
    "lim=n_test_samples\n",
    "\n",
    "precision_background_list=[]\n",
    "precision_cancer_list=[]\n",
    "precision_normal_list=[]\n",
    "\n",
    "recall_background_list=[]\n",
    "recall_cancer_list=[]\n",
    "recall_normal_list=[]\n",
    "\n",
    "f1_background_list=[]\n",
    "f1_cancer_list=[]\n",
    "f1_normal_list=[]\n",
    "list_3cls=[]\n",
    "\n",
    "for n in range(0, lim): \n",
    "    ground_truth = rgb_to_onehot_3cls(masks[n])\n",
    "    if(np.sum(np.sum(ground_truth[:,:,0]))!=0 and np.sum(np.sum(ground_truth[:,:,1]))!=0 and np.sum(np.sum(ground_truth[:,:,2]))!=0):\n",
    "        list_3cls.append(n)\n",
    "\n",
    "list_3cls = np.array(list_3cls)\n",
    "n_3cls = (len((list_3cls)))\n",
    "n_elem_group = math.floor((n_test_samples-n_3cls)/n_3cls)\n",
    "print(n_elem_group)\n",
    "list_left=[]\n",
    "\n",
    "for n in range(0, lim):\n",
    "    if n not in list_3cls:\n",
    "        list_left.append(n)\n",
    "        \n",
    "list_left = np.random.permutation(np.array(list_left))\n",
    "n_list_left = len(list_left)       \n",
    "B = np.reshape(list_left[:(n_elem_group*n_3cls)],(-1,n_elem_group))\n",
    "A = np.reshape(list_3cls,(-1,1))\n",
    "\n",
    "print(B.shape)\n",
    "print(A.shape)\n",
    "\n",
    "groups = np.concatenate((A, B), axis=1)\n",
    "\n",
    "print (groups)\n",
    "\n",
    "precision_background_list=[]\n",
    "precision_cancer_list=[]\n",
    "precision_normal_list=[]\n",
    "\n",
    "recall_background_list=[]\n",
    "recall_cancer_list=[]\n",
    "recall_normal_list=[]\n",
    "\n",
    "f1_background_list=[]\n",
    "f1_cancer_list=[]\n",
    "f1_normal_list=[]\n",
    "\n",
    "for i in range(0,n_3cls):\n",
    "    TP_b=0\n",
    "    FP_b=0\n",
    "    FN_b=0\n",
    "    TN_b=0\n",
    "\n",
    "    TP_n=0\n",
    "    FP_n=0\n",
    "    FN_n=0\n",
    "    TN_n=0\n",
    "\n",
    "    TP_c=0\n",
    "    FP_c=0\n",
    "    FN_c=0\n",
    "    TN_c=0\n",
    "    for j in range(0,n_elem_group+1):\n",
    "           \n",
    "        true_positives= np.zeros(shape=(512,512,3))\n",
    "        false_positives= np.zeros(shape=(512,512,3))\n",
    "        false_negatives= np.zeros(shape=(512,512,3))\n",
    "        test_res_sample =  np.array(rgb_to_onehot_3cls(CRF_res[groups[i,j]]))\n",
    "        \n",
    "        ground_truth = rgb_to_onehot_3cls(masks[groups[i,j]])\n",
    "        most_prob = np.zeros(shape = [patch_size, patch_size, n_classes])\n",
    "\n",
    "        most_prob[:,:,0] = (np.array(test_res_sample[:,:,0] == np.fmax(np.fmax(test_res_sample[:,:,0], test_res_sample[:,:,1]),((test_res_sample[:,:,2]))),dtype = 'float32'))\n",
    "        most_prob[:,:,1] = (np.array(test_res_sample[:,:,1] == np.fmax(np.fmax(test_res_sample[:,:,0], test_res_sample[:,:,1]),((test_res_sample[:,:,2]))),dtype = 'float32'))\n",
    "        most_prob[:,:,2] = (np.array(test_res_sample[:,:,2] == np.fmax(np.fmax(test_res_sample[:,:,0], test_res_sample[:,:,1]),((test_res_sample[:,:,2]))),dtype = 'float32'))\n",
    "        \n",
    "        for n in range(0,3):\n",
    "            true_positives[:,:,n] = np.multiply(most_prob[:,:,n], ground_truth[:,:,n])\n",
    "            false_positives[:,:,n] = (most_prob[:,:,n]-1) == ground_truth[:,:,n]\n",
    "            false_negatives[:,:,n] = most_prob[:,:,n] == (ground_truth[:,:,n] - 1)\n",
    "\n",
    "        precision_background = TP_b/(TP_b+FP_b+epsi)\n",
    "        recall_background = TP_b/(TP_b+FN_b+epsi)\n",
    "        f1_background = 2 * (precision_background * recall_background/(precision_background + recall_background + epsi))\n",
    "\n",
    "        TP_b=TP_b+ np.sum(np.sum(np.sum(true_positives[:,:,0])))\n",
    "        FP_b=FP_b+ np.sum(np.sum(np.sum(false_positives[:,:,0])))\n",
    "        FN_b=FN_b+ np.sum(np.sum(np.sum(false_negatives[:,:,0])))\n",
    "\n",
    "        TP_n+=np.sum(np.sum(np.sum(true_positives[:,:,1])))\n",
    "        FP_n+=np.sum(np.sum(np.sum(false_positives[:,:,1])))\n",
    "        FN_n+=np.sum(np.sum(np.sum(false_negatives[:,:,1])))\n",
    "\n",
    "        TP_c+=np.sum(np.sum(np.sum(true_positives[:,:,2])))\n",
    "        FP_c+=np.sum(np.sum(np.sum(false_positives[:,:,2])))\n",
    "        FN_c+=np.sum(np.sum(np.sum(false_negatives[:,:,2])))\n",
    "\n",
    "    if i==n_3cls-1 and j==n_elem_group:\n",
    "        \n",
    "        for t in range(n_elem_group*n_3cls ,n_list_left):\n",
    "            test_res_sample =  np.array(test_res[t,:,:,:])\n",
    "            ground_truth = rgb_to_onehot_3cls(masks[t])\n",
    "            most_prob = np.zeros(shape = [patch_size, patch_size, n_classes])\n",
    "            \n",
    "            most_prob[:,:,0] = (np.array(test_res_sample[:,:,0] == np.fmax(np.fmax(test_res_sample[:,:,0], test_res_sample[:,:,1]),((test_res_sample[:,:,2]))),dtype = 'float32'))\n",
    "            most_prob[:,:,1] = (np.array(test_res_sample[:,:,1] == np.fmax(np.fmax(test_res_sample[:,:,0], test_res_sample[:,:,1]),((test_res_sample[:,:,2]))),dtype = 'float32'))\n",
    "            most_prob[:,:,2] = (np.array(test_res_sample[:,:,2] == np.fmax(np.fmax(test_res_sample[:,:,0], test_res_sample[:,:,1]),((test_res_sample[:,:,2]))),dtype = 'float32'))\n",
    "        \n",
    "            for n in range(0,3):\n",
    "                true_positives[:,:,n] = np.multiply(most_prob[:,:,n], ground_truth[:,:,n])\n",
    "                false_positives[:,:,n] = (most_prob[:,:,n]-1) == ground_truth[:,:,n]\n",
    "                false_negatives[:,:,n] = most_prob[:,:,n] == (ground_truth[:,:,n] - 1)\n",
    "\n",
    "            precision_background = TP_b/(TP_b+FP_b+epsi)\n",
    "            recall_background = TP_b/(TP_b+FN_b+epsi)\n",
    "            f1_background = 2 * (precision_background * recall_background/(precision_background + recall_background + epsi))\n",
    "\n",
    "            TP_b=TP_b+ np.sum(np.sum(np.sum(true_positives[:,:,0])))\n",
    "            FP_b=FP_b+ np.sum(np.sum(np.sum(false_positives[:,:,0])))\n",
    "            FN_b=FN_b+ np.sum(np.sum(np.sum(false_negatives[:,:,0])))\n",
    "\n",
    "            TP_n+=np.sum(np.sum(np.sum(true_positives[:,:,1])))\n",
    "            FP_n+=np.sum(np.sum(np.sum(false_positives[:,:,1])))\n",
    "            FN_n+=np.sum(np.sum(np.sum(false_negatives[:,:,1])))\n",
    "\n",
    "            TP_c+=np.sum(np.sum(np.sum(true_positives[:,:,2])))\n",
    "            FP_c+=np.sum(np.sum(np.sum(false_positives[:,:,2])))\n",
    "            FN_c+=np.sum(np.sum(np.sum(false_negatives[:,:,2])))\n",
    "      \n",
    "    precision_normal = TP_n/(TP_n+FP_n+epsi)\n",
    "    recall_normal = TP_n/(TP_n+FN_n+epsi)\n",
    "    f1_normal = 2 * (precision_normal * recall_normal/(precision_normal + recall_normal + epsi))\n",
    "\n",
    "    precision_cancer = TP_c/(TP_c+FP_c+epsi)\n",
    "    recall_cancer = TP_c/(TP_c+FN_c+epsi)\n",
    "    f1_cancer = 2 * (precision_cancer * recall_cancer/(precision_cancer + recall_cancer + epsi))\n",
    "\n",
    "    precision_background_list.append(precision_background)\n",
    "    precision_cancer_list.append(precision_cancer)\n",
    "    precision_normal_list.append(precision_normal)\n",
    "\n",
    "    recall_background_list.append(recall_background)\n",
    "    recall_cancer_list.append(recall_cancer)\n",
    "    recall_normal_list.append(recall_normal)\n",
    "\n",
    "    f1_background_list.append(f1_background)\n",
    "    f1_cancer_list.append(f1_cancer)\n",
    "    f1_normal_list.append(f1_normal)\n",
    "\n",
    "\n",
    "    \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(f1_background_list))\n",
    "print(n_3cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp='B'\n",
    "csv_file = 'Experiments_results_crossFINAL_CRF12_'+exp+'_groups.csv'\n",
    "if os.path.exists(csv_file) == 0:\n",
    "    print('The file does not exist, New file is made')\n",
    "    with open(csv_file, 'w') as csvfile:\n",
    "        filewriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "        filewriter.writerow(['Exp','Source', 'Metric', 'Value'])\n",
    "        for i in range(0,n_3cls):\n",
    "            filewriter.writerow([exp,'Background', 'Precision', precision_background_list[i]])\n",
    "            filewriter.writerow([exp,'Background', 'Recall', recall_background_list[i]])\n",
    "            filewriter.writerow([exp,'Background', 'F1 score', f1_background_list[i]])\n",
    "        for i in range(0,n_3cls):\n",
    "            filewriter.writerow([exp,'Normal', 'Precision', precision_normal_list[i]])\n",
    "            filewriter.writerow([exp,'Normal', 'Recall', recall_normal_list[i]])\n",
    "            filewriter.writerow([exp,'Normal', 'F1 score', f1_normal_list[i]])\n",
    "        for i in range(0,n_3cls):\n",
    "            filewriter.writerow([exp,'Cancer', 'Precision', precision_cancer_list[i]])\n",
    "            filewriter.writerow([exp,'Cancer', 'Recall', recall_cancer_list[i]])\n",
    "            filewriter.writerow([exp,'Cancer', 'F1 score', f1_cancer_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# colors = {'Background': 'white', 'Normal':('#9FD3F9'), 'Cancer':('#E7C0B2')}\n",
    "colors = {'Background': 'white', 'Normal':('#FF00FF'), 'Cancer':'black'}\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "fig = plt.figure()\n",
    "sns.set(style='ticks')\n",
    "# col = artist.get_facecolor()\n",
    "# artist.setedgecolor(col)\n",
    "ax = plt.subplot(111)\n",
    "ax = sns.boxplot(x=\"Metric\", y=\"Value\", hue=\"Source\", data=df, palette=colors, fliersize='0.4',showmeans=True)\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.12), ncol=3)\n",
    "plt.xlabel(None)\n",
    "plt.ylabel('Performance score')\n",
    "plt.setp(ax.lines, color='gray')\n",
    "sns.despine(offset=0., trim=True)\n",
    "plt.savefig('CrossFINAL_CRF12_'+exp+'_groups.png')\n",
    "\n",
    "plt.show()\n",
    "plt.clf()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metrics per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate precision and recall per tissue type\n",
    "epsi=0.00000001\n",
    "masks = [cv2.imread(file) for file in sorted(glob.glob(os.path.join(Test_path+'/Masks/Group1/', '*-labels.png')))]\n",
    "\n",
    "\n",
    "for i in range(0, len(masks)):\n",
    "    #b,g,r = cv2.split(masks[i])\n",
    "    masks[i] = (cv2.cvtColor(masks[i], cv2.COLOR_BGR2RGB))\n",
    "\n",
    "lim=n_test_samples\n",
    "\n",
    "\n",
    "TP_b=0\n",
    "FP_b=0\n",
    "FN_b=0\n",
    "TN_b=0\n",
    "\n",
    "TP_n=0\n",
    "FP_n=0\n",
    "FN_n=0\n",
    "TN_n=0\n",
    "\n",
    "TP_c=0\n",
    "FP_c=0\n",
    "FN_c=0\n",
    "TN_c=0\n",
    "\n",
    "\n",
    "for n in range(0, lim): #with scalling\n",
    "    \n",
    "    true_positives= np.zeros(shape=(512,512,3))\n",
    "    false_positives= np.zeros(shape=(512,512,3))\n",
    "    false_negatives= np.zeros(shape=(512,512,3))\n",
    "    test_res_sample =  np.array(rgb_to_onehot_3cls(CRF_res[n]))\n",
    "    ground_truth = rgb_to_onehot_3cls(masks[n])\n",
    "    most_prob = np.zeros(shape = [patch_size, patch_size, n_classes])\n",
    "    \n",
    "    most_prob[:,:,0] = (np.array(test_res_sample[:,:,0] == np.fmax(np.fmax(test_res_sample[:,:,0], test_res_sample[:,:,1]),((test_res_sample[:,:,2]))),dtype = 'float32'))\n",
    "    most_prob[:,:,1] = (np.array(test_res_sample[:,:,1] == np.fmax(np.fmax(test_res_sample[:,:,0], test_res_sample[:,:,1]),((test_res_sample[:,:,2]))),dtype = 'float32'))\n",
    "    most_prob[:,:,2] = (np.array(test_res_sample[:,:,2] == np.fmax(np.fmax(test_res_sample[:,:,0], test_res_sample[:,:,1]),((test_res_sample[:,:,2]))),dtype = 'float32'))\n",
    "\n",
    "    for i in range(0,3):\n",
    "        true_positives[:,:,i] = np.multiply(most_prob[:,:,i], ground_truth[:,:,i])\n",
    "        false_positives[:,:,i] = (most_prob[:,:,i]-1) == ground_truth[:,:,i]\n",
    "        false_negatives[:,:,i] = most_prob[:,:,i] == (ground_truth[:,:,i] - 1)\n",
    "        true_negatives = np.multiply((most_prob - 1),(ground_truth - 1))\n",
    "        \n",
    "    TP_b=TP_b+ np.sum(np.sum(np.sum(true_positives[:,:,0])))\n",
    "    FP_b=FP_b+ np.sum(np.sum(np.sum(false_positives[:,:,0])))\n",
    "    FN_b=FN_b+ np.sum(np.sum(np.sum(false_negatives[:,:,0])))\n",
    "    TN_b=TN_b+ np.sum(np.sum(np.sum(true_negatives[:,:,0])))\n",
    "\n",
    "    TP_n+=np.sum(np.sum(np.sum(true_positives[:,:,1])))\n",
    "    FP_n+=np.sum(np.sum(np.sum(false_positives[:,:,1])))\n",
    "    FN_n+=np.sum(np.sum(np.sum(false_negatives[:,:,1])))\n",
    "    TN_n+=np.sum(np.sum(np.sum(true_negatives[:,:,1])))\n",
    "\n",
    "    TP_c+=np.sum(np.sum(np.sum(true_positives[:,:,2])))\n",
    "    FP_c+=np.sum(np.sum(np.sum(false_positives[:,:,2])))\n",
    "    FN_c+=np.sum(np.sum(np.sum(false_negatives[:,:,2])))\n",
    "    TN_c+=np.sum(np.sum(np.sum(true_negatives[:,:,2])))\n",
    "\n",
    "precision_background = TP_b/(TP_b+FP_b+epsi)\n",
    "recall_background = TP_b/(TP_b+FN_b+epsi)\n",
    "specificity_background = TN_b/(TN_b+FP_b+epsi)\n",
    "f1_background = 2 * (precision_background * recall_background/(precision_background + recall_background + epsi))\n",
    "\n",
    "\n",
    "precision_normal = TP_n/(TP_n+FP_n+epsi)\n",
    "recall_normal = TP_n/(TP_n+FN_n+epsi)\n",
    "specificity_normal = TN_n/(TN_n+FP_n+epsi)\n",
    "FNR_n=FN_n/(FN_n+TP_n+epsi)\n",
    "f1_normal = 2 * (precision_normal * recall_normal/(precision_normal + recall_normal + epsi))\n",
    "\n",
    "\n",
    "precision_cancer = TP_c/(TP_c+FP_c+epsi)\n",
    "recall_cancer = TP_c/(TP_c+FN_c+epsi)\n",
    "specificity_cancer = TN_c/(TN_c+FP_c+epsi)\n",
    "f1_cancer = 2 * (precision_cancer * recall_cancer/(precision_cancer + recall_cancer + epsi))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((f1_background))\n",
    "print((f1_normal))\n",
    "\n",
    "\n",
    "print(recall_cancer)\n",
    "print(precision_cancer)\n",
    "print((f1_cancer))\n",
    "\n",
    "\n",
    "print(specificity_normal)\n",
    "print(specificity_cancer)\n",
    "print(specificity_background)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(np.sum(np.sum(false_negatives[:,:,2])))\n",
    "np.sum(np.sum(np.sum(most_prob[:,:,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'Experiments_crossFINAL_CRF12_Good_total_mean.csv'\n",
    "if os.path.exists(csv_file) == 0:\n",
    "    print('The file does not exist, New file is made')\n",
    "    with open(csv_file, 'w') as csvfile:\n",
    "        filewriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "        filewriter.writerow(['Exp','Source', 'Metric', 'Value'])\n",
    "        filewriter.writerow([exp,'Background', 'Precision', precision_background])\n",
    "        filewriter.writerow([exp,'Background', 'Recall', recall_background])\n",
    "        filewriter.writerow([exp,'Background', 'F1 score', f1_background])\n",
    "        filewriter.writerow([exp,'Normal', 'Precision', precision_normal])\n",
    "        filewriter.writerow([exp,'Normal', 'Recall', recall_normal])\n",
    "        filewriter.writerow([exp,'Normal', 'F1 score', f1_normal])\n",
    "        filewriter.writerow([exp,'Cancer', 'Precision', precision_cancer])\n",
    "        filewriter.writerow([exp,'Cancer', 'Recall', recall_cancer])\n",
    "        filewriter.writerow([exp,'Cancer', 'F1 score', f1_cancer])\n",
    "else:\n",
    "    print('The file exists, New rows are added')\n",
    "    with open(csv_file, 'a') as csvfile:\n",
    "        filewriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        \n",
    "        filewriter.writerow([exp,'Background', 'Precision', precision_background])\n",
    "        filewriter.writerow([exp,'Background', 'Recall', recall_background])\n",
    "        filewriter.writerow([exp,'Background', 'F1 score', f1_background])\n",
    "        filewriter.writerow([exp,'Normal', 'Precision', precision_normal])\n",
    "        filewriter.writerow([exp,'Normal', 'Recall', recall_normal])\n",
    "        filewriter.writerow([exp,'Normal', 'F1 score', f1_normal])\n",
    "        filewriter.writerow([exp,'Cancer', 'Precision', precision_cancer])\n",
    "        filewriter.writerow([exp,'Cancer', 'Recall', recall_cancer])\n",
    "        filewriter.writerow([exp,'Cancer', 'F1 score', f1_cancer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only after the end\n",
    "colors = {'Background': 'white', 'Normal':('#FF00FF'), 'Cancer':('black')}\n",
    "\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "fig = plt.figure()\n",
    "sns.set(style='ticks')\n",
    "ax = plt.subplot(111)\n",
    "ax = sns.swarmplot(x=\"Metric\", y=\"Value\", hue=\"Source\",palette=colors, data=df, dodge=True, linewidth=0.6)\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.13), ncol=3)\n",
    "\n",
    "plt.xlabel(None)\n",
    "ax.axis([None, None, -0.05, 1.05])\n",
    "plt.ylabel('Performance score')\n",
    "plt.setp(ax.lines, color='gray')\n",
    "# plt.title('Performance score in five models', y=1.15)\n",
    "sns.despine(offset=0.5, trim=True)\n",
    "plt.savefig('CrossFINAL_CRF12_good_all.png')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.clf()\n",
    "plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
