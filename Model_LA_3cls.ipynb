{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lung adenocarcinoma cancer detection pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "from skimage import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np \n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, Dropout, concatenate, Reshape, Permute, Lambda, BatchNormalization\n",
    "from keras.activations import softmax\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, History\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
    "from keras_preprocessing import image\n",
    "\n",
    "import glob \n",
    "import cv2\n",
    "from scipy import misc\n",
    "import sys\n",
    "# import shutil\n",
    "\n",
    "from zipfile import ZipFile \n",
    "\n",
    "from keras.layers import Lambda\n",
    "from keras import backend as K\n",
    "\n",
    "import imageio\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import imageio\n",
    "\n",
    "import pandas as pd\n",
    "import six\n",
    "import csv\n",
    " \n",
    "\n",
    "ia.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def load_patch(patch):\n",
    "    p = io.imread(patch)\n",
    "    p_array = np.asarray(p, dtype = \"int32\")\n",
    "    return p_array \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask generator into one-hot\n",
    "\n",
    "patch_size = 512\n",
    "batch_size = 16\n",
    "\n",
    "class MasksBatchGenerator(DirectoryIterator):\n",
    "    \n",
    "    def __init__(self,\n",
    "                directory, \n",
    "                image_data_generator,\n",
    "                target_size = (patch_size, patch_size),\n",
    "                num_channels = 1,\n",
    "                classes=None, \n",
    "                class_mode=None,\n",
    "                batch_size=batch_size, shuffle=True,\n",
    "                seed=None,\n",
    "                data_format=None,\n",
    "                save_to_dir=None,\n",
    "                save_prefix='',\n",
    "                save_format='png',\n",
    "                follow_links=False,\n",
    "                subset=None,\n",
    "                interpolation='nearest',\n",
    "                preprocessing_function= None):\n",
    "\n",
    "        super(MasksBatchGenerator,self).__init__(directory, \n",
    "                image_data_generator,                                              \n",
    "                target_size=target_size,                      \n",
    "                classes=classes,\n",
    "                class_mode=class_mode,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=shuffle,\n",
    "                seed=seed,\n",
    "                data_format=data_format,\n",
    "                save_to_dir=save_to_dir,\n",
    "                save_prefix=save_prefix,\n",
    "                save_format=save_format,\n",
    "                follow_links=follow_links,\n",
    "                subset=subset,\n",
    "                interpolation=interpolation)\n",
    "\n",
    "        self.image_shape = (target_size[0],target_size[1],num_channels)\n",
    "        self.preprocessing_function = preprocessing_function\n",
    "        \n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        \n",
    "        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype = K.floatx())\n",
    "        \n",
    "        for i, j in enumerate(index_array):\n",
    "            \n",
    "            fname = self.filenames[j]\n",
    "\n",
    "            img = cv2.cvtColor(cv2.imread(os.path.join(self.directory, fname)), cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            if self.preprocessing_function:\n",
    "                img = self.preprocessing_function(img)\n",
    "                \n",
    "            batch_x[i] = img\n",
    "            \n",
    "        return batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch generator\n",
    "\n",
    "class PatchBatchGenerator(DirectoryIterator):\n",
    "    \n",
    "    def __init__(self,\n",
    "                directory, \n",
    "                image_data_generator,\n",
    "                target_size = (patch_size, patch_size),\n",
    "                num_channels = 3,\n",
    "                color_mode = \"rgb\",\n",
    "                classes=None, \n",
    "                class_mode=None,\n",
    "                batch_size=batch_size, shuffle=True,\n",
    "                seed=None,\n",
    "                data_format=None,\n",
    "                save_to_dir=None,\n",
    "                save_prefix='',\n",
    "                save_format='jpg',\n",
    "                follow_links=False,\n",
    "                subset=None,\n",
    "                interpolation='nearest',\n",
    "                preprocessing_function= None):\n",
    "\n",
    "        super(PatchBatchGenerator,self).__init__(directory, \n",
    "                image_data_generator,\n",
    "                target_size=target_size,                      \n",
    "                classes=classes,\n",
    "                class_mode=class_mode,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=shuffle,\n",
    "                seed=seed,\n",
    "                data_format=data_format,\n",
    "                save_to_dir=save_to_dir,\n",
    "                save_prefix=save_prefix,\n",
    "                save_format=save_format,\n",
    "                follow_links=follow_links,\n",
    "                subset=subset,\n",
    "                interpolation=interpolation)\n",
    "\n",
    "        self.image_shape = (target_size[0],target_size[1],num_channels)\n",
    "        \n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        \n",
    "        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype = K.floatx())\n",
    "        \n",
    "        for i, j in enumerate(index_array):\n",
    "            \n",
    "            fname = self.filenames[j]\n",
    "            img = cv2.cvtColor(cv2.imread(os.path.join(self.directory, fname)), cv2.COLOR_BGR2RGB)        \n",
    "\n",
    "            batch_x[i] = img/255.0\n",
    "            \n",
    "        return batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask generator into one-hot with statial augmentation\n",
    "\n",
    "\n",
    "class MasksBatchGeneratorAug(DirectoryIterator):\n",
    "    \n",
    "    def __init__(self,\n",
    "                directory, \n",
    "                image_data_generator,\n",
    "                target_size = (patch_size, patch_size),\n",
    "                num_channels = 1,\n",
    "                classes=None, \n",
    "                class_mode=None,\n",
    "                batch_size=batch_size, shuffle=True,\n",
    "                seed=None,\n",
    "                data_format=None,\n",
    "                save_to_dir=None,\n",
    "                save_prefix='',\n",
    "                save_format='png',\n",
    "                follow_links=False,\n",
    "                subset=None,\n",
    "                interpolation='nearest',\n",
    "                preprocessing_function= None,\n",
    "                preprocessing_function_space= None):\n",
    "\n",
    "        super(MasksBatchGeneratorAug,self).__init__(directory, \n",
    "                image_data_generator,\n",
    "                target_size=target_size,                      \n",
    "                classes=classes,\n",
    "                class_mode=class_mode,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=shuffle,\n",
    "                seed=seed,\n",
    "                data_format=data_format,\n",
    "                save_to_dir=save_to_dir,\n",
    "                save_prefix=save_prefix,\n",
    "                save_format=save_format,\n",
    "                follow_links=follow_links,\n",
    "                subset=subset,\n",
    "                interpolation=interpolation)\n",
    "\n",
    "        self.image_shape = (target_size[0],target_size[1],num_channels)\n",
    "        self.preprocessing_function_space = preprocessing_function_space\n",
    "        self.preprocessing_function = preprocessing_function\n",
    "        \n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        \n",
    "        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype = K.floatx())\n",
    "        \n",
    "        for i, j in enumerate(index_array):\n",
    "            \n",
    "            fname = self.filenames[j]\n",
    "            img = cv2.cvtColor(cv2.imread(os.path.join(self.directory, fname)), cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            if self.preprocessing_function_space:\n",
    "                img= self.preprocessing_function_space(img)\n",
    "            \n",
    "            if self.preprocessing_function:\n",
    "                img = self.preprocessing_function(img)\n",
    "                \n",
    "            batch_x[i] = img\n",
    "            \n",
    "        return batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch generator with statial augmentation\n",
    "\n",
    "\n",
    "class PatchBatchGeneratorAug(DirectoryIterator):\n",
    "    \n",
    "    def __init__(self,\n",
    "                directory, \n",
    "                image_data_generator,\n",
    "                target_size = (patch_size, patch_size),\n",
    "                num_channels = 3,\n",
    "                color_mode = \"rgb\",\n",
    "                classes=None, \n",
    "                class_mode=None,\n",
    "                batch_size=batch_size, shuffle=True,\n",
    "                seed=None,\n",
    "                data_format=None,\n",
    "                save_to_dir=None,\n",
    "                save_prefix='',\n",
    "                save_format='jpg',\n",
    "                follow_links=False,\n",
    "                subset=None,\n",
    "                interpolation='nearest',\n",
    "                preprocessing_function_space= None,\n",
    "                preprocessing_function= None):\n",
    "\n",
    "        super(PatchBatchGeneratorAug,self).__init__(directory, \n",
    "                image_data_generator,\n",
    "                target_size=target_size,                      \n",
    "                classes=classes,\n",
    "                class_mode=class_mode,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=shuffle,\n",
    "                seed=seed,\n",
    "                data_format=data_format,\n",
    "                save_to_dir=save_to_dir,\n",
    "                save_prefix=save_prefix,\n",
    "                save_format=save_format,\n",
    "                follow_links=follow_links,\n",
    "                subset=subset,\n",
    "                interpolation=interpolation)\n",
    "\n",
    "        self.image_shape = (target_size[0],target_size[1],num_channels)\n",
    "        self.preprocessing_function_space = preprocessing_function_space\n",
    "        \n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        \n",
    "        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype = K.floatx())\n",
    "        \n",
    "        for i, j in enumerate(index_array):\n",
    "            \n",
    "            fname = self.filenames[j]\n",
    "\n",
    "            img = cv2.cvtColor(cv2.imread(os.path.join(self.directory, fname)), cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            if self.preprocessing_function_space:\n",
    "                img= self.preprocessing_function_space(img)\n",
    "                \n",
    "            batch_x[i] = img/255.0\n",
    "            \n",
    "        return batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch generator with spatial and brightness augmentation\n",
    "\n",
    "class PatchBatchGeneratorAugCol(DirectoryIterator):\n",
    "    \n",
    "    def __init__(self,\n",
    "                directory, \n",
    "                image_data_generator,\n",
    "                target_size = (patch_size, patch_size),\n",
    "                num_channels = 3,\n",
    "                color_mode = \"rgb\",\n",
    "                classes=None, \n",
    "                class_mode=None,\n",
    "                batch_size=batch_size, shuffle=True,\n",
    "                seed=None,\n",
    "                data_format=None,\n",
    "                save_to_dir=None,\n",
    "                save_prefix='',\n",
    "                save_format='jpg',\n",
    "                follow_links=False,\n",
    "                subset=None,\n",
    "                interpolation='nearest',\n",
    "                preprocessing_function_colour = None,\n",
    "                preprocessing_function_space= None):\n",
    "\n",
    "        super(PatchBatchGeneratorAugCol,self).__init__(directory, \n",
    "                image_data_generator,\n",
    "                target_size=target_size,                      \n",
    "                classes=classes,\n",
    "                class_mode=class_mode,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=shuffle,\n",
    "                seed=seed,\n",
    "                data_format=data_format,\n",
    "                save_to_dir=save_to_dir,\n",
    "                save_prefix=save_prefix,\n",
    "                save_format=save_format,\n",
    "                follow_links=follow_links,\n",
    "                subset=subset,\n",
    "                interpolation=interpolation)\n",
    "\n",
    "        self.image_shape = (target_size[0],target_size[1],num_channels)\n",
    "        self.preprocessing_function_space = preprocessing_function_space\n",
    "        self.preprocessing_function_colour = preprocessing_function_colour\n",
    "        \n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        \n",
    "        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype = K.floatx())\n",
    "        \n",
    "        for i, j in enumerate(index_array):\n",
    "            \n",
    "            fname = self.filenames[j]\n",
    "\n",
    "            img = cv2.cvtColor(cv2.imread(os.path.join(self.directory, fname)), cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            if self.preprocessing_function_space:\n",
    "                img= self.preprocessing_function_space(img)\n",
    "                \n",
    "            if self.preprocessing_function_colour:\n",
    "                img= self.preprocessing_function_colour(img)\n",
    "                \n",
    "            batch_x[i] = img/255.0\n",
    "            \n",
    "        return batch_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open image function\n",
    "\n",
    "def open_image(path):\n",
    "  newImage = Image.open(path)\n",
    "  return newImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertor from masks with many classes(colours) to one-hot vector with only 3 classes\n",
    "\n",
    "## 0 is background, 1 is healthy, 2 is cancer\n",
    "def rgb_to_onehot_3cls(rgb_arr):\n",
    "    \n",
    "    color_dict = {0: [255, 255, 255], # white- background  bgr rgb GOOD\n",
    "              1: [255, 0, 255], # magenta - normal \n",
    "              2: [102, 102, 102], # gray- other GOOD\n",
    "              3: [50, 160, 50], # also something green- acinary tumour\n",
    "              4: [0, 255, 0], # green lime- lepidic tumour GOOD\n",
    "              5: [0, 0, 0], # black- solid tumour GOOD\n",
    "              6: [0, 75, 0], # - darker gree tumour\n",
    "              7: [130, 170, 130], # light green- micropapollary tumour \n",
    "                 }          \n",
    "             \n",
    "    num_classes = len(color_dict)-5\n",
    "    shape = rgb_arr.shape[:2]\n",
    "    arr = np.zeros( shape, dtype=np.int8 )\n",
    "    \n",
    "    for i, cls in color_dict.items():\n",
    "        \n",
    "        if i == 0:\n",
    "            \n",
    "            mask0 = rgb_arr[:, :, 0] == cls[0]\n",
    "            mask1 = rgb_arr[:, :, 1] == cls[1]\n",
    "            mask2 = rgb_arr[:, :, 2] == cls[2]\n",
    "            mask = np.logical_and(np.logical_and(mask0, mask1), mask2)\n",
    "            arr[mask] = i\n",
    "            \n",
    "        elif i == 1 or i == 2:\n",
    "            \n",
    "            mask0 = rgb_arr[:, :, 0] == cls[0]\n",
    "            mask1 = rgb_arr[:, :, 1] == cls[1]\n",
    "            mask2 = rgb_arr[:, :, 2] == cls[2]\n",
    "            mask = np.logical_and(np.logical_and(mask0, mask1), mask2)\n",
    "            arr[mask] = 1\n",
    "            \n",
    "        elif i == 3 or i == 4 or i == 5 or i == 6 or i == 7:\n",
    "            \n",
    "            mask0 = rgb_arr[:, :, 0] == cls[0]\n",
    "            mask1 = rgb_arr[:, :, 1] == cls[1]\n",
    "            mask2 = rgb_arr[:, :, 2] == cls[2]\n",
    "            mask = np.logical_and(np.logical_and(mask0, mask1), mask2)\n",
    "            arr[mask] = 2\n",
    "        \n",
    "    arr_vec=np.zeros((arr.shape[0], arr.shape[1], num_classes))\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        \n",
    "        mask = (arr == i)\n",
    "        arr_vec[:, :, i][mask] = 1 \n",
    "        \n",
    "    return arr_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertor from one-hot to RGB image with 3 colours\n",
    "\n",
    "def onehot_to_rgb_3cls(onehot):\n",
    "    \n",
    "    color_dict = {0: [255, 255, 255], # white- background  bgr rgb\n",
    "              1: [255, 0, 255], # non-cancer -blue\n",
    "              2: [0, 0, 0], # cancer -red\n",
    "                 }\n",
    "    single_layer = np.argmax(onehot, axis=-1)\n",
    "    output = np.zeros( onehot.shape[:2]+(3,) )\n",
    "    for k in color_dict.keys():\n",
    "        output[single_layer==k] = color_dict[k]\n",
    "    return np.uint8(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brightness augmentation function\n",
    "\n",
    "def brightness_augmentation(factor):\n",
    "    factor = factor\n",
    "    \n",
    "    def augment(img): \n",
    "\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV) #convert to hsv\n",
    "        hsv = np.array(hsv, dtype=np.float64)\n",
    "        hsv[:, :, 2] = hsv[:, :, 2] * (factor + np.random.uniform()) #scale channel V uniformly\n",
    "        hsv[:, :, 2][hsv[:, :, 2] > 255] = 255 #reset out of range values\n",
    "        rgb = cv2.cvtColor(np.array(hsv, dtype=np.uint8), cv2.COLOR_HSV2RGB)     \n",
    "        augment = rgb\n",
    "        return augment\n",
    "    \n",
    "    return augment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted categorical cross-entropy function\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        \n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score measurements\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "        \n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "\n",
    "    return fbeta_score(y_true, y_pred, beta=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics visualisation function\n",
    "\n",
    "def render_table(data, col_width = 3.0, row_height = 0.625, font_size = 14,\n",
    "                     header_color = '#F8F8FF', row_colors = ['w'], edge_color = '#D3D3D3',\n",
    "                     bbox = [0, 0, 1, 1], header_columns = 0,\n",
    "                     ax = None, **kwargs):\n",
    "    if ax is None:\n",
    "        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])\n",
    "        fig, ax = plt.subplots(figsize=size)\n",
    "        ax.axis('off')\n",
    "\n",
    "    mpl_table = ax.table(cellText = data.values, bbox = bbox, colLabels = data.columns, **kwargs)\n",
    "\n",
    "    mpl_table.auto_set_font_size(False)\n",
    "    mpl_table.set_fontsize(font_size)\n",
    "\n",
    "    for k, cell in six.iteritems(mpl_table._cells):\n",
    "        cell.set_edgecolor(edge_color)\n",
    "        if k[0] == 0 or k[1] < header_columns:\n",
    "            cell.set_text_props(weight = 'bold', color = '#000000')\n",
    "            cell.set_facecolor(header_color)\n",
    "        else:\n",
    "            cell.set_facecolor(row_colors[k[0]%len(row_colors)])\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model parameters (inputs)\n",
    "\n",
    "n_classes = 3 \n",
    "patch_size = 512 #both height and width \n",
    "\n",
    "batch_size = 16\n",
    "n_epoch = 100\n",
    "\n",
    "learning_rate = 0.01\n",
    "patience = 30\n",
    "\n",
    "# Weights\n",
    "class_weights = [1,1,2]\n",
    "type_loss_function = weighted_categorical_crossentropy(class_weights)\n",
    "# type_loss_function = keras.losses.categorical_crossentropy\n",
    "\n",
    "# Spatial augmentation function\n",
    "seq = iaa.Sometimes(0.75,iaa.SomeOf((1,3),[iaa.Affine(rotate=(0, 360),cval=(255)), iaa.Fliplr(0.5), iaa.Flipud(0.5)], random_order=True))\n",
    "seq_det = seq.to_deterministic()\n",
    "\n",
    "# Colour augmentation\n",
    "\n",
    "colour_shift = 0.0500\n",
    "colour_augmentation_function = brightness_augmentation(colour_shift)\n",
    "\n",
    "# Set time experiment \n",
    "\n",
    "current_date = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Experiment order\n",
    "\n",
    "Exp = '_Exp_512'\n",
    "\n",
    "# Directories\n",
    "\n",
    "history_path = os.path.dirname(os.path.realpath(\"Train\")) + '/History_data_'\n",
    "weights_path = os.path.dirname(os.path.realpath(\"Train\")) + '/Weights_data_'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "Test_path = \"/home/guest/DL/Teodora/Project/Test512\"\n",
    "Train_path = \"/home/guest/DL/Teodora/Project/Train512\"\n",
    "Val_path = \"/home/guest/DL/Teodora/Project/Validation512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#U-net implementation\n",
    "\n",
    "inputs = Input((patch_size, patch_size, 3))\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', dilation_rate = 2)(inputs)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', dilation_rate = 2)(conv1)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "print(conv1.shape)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "\n",
    "print(conv2.shape)\n",
    "\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "print(conv3.shape)\n",
    "\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "print(conv4.shape)\n",
    "\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "print(conv5.shape)\n",
    "\n",
    "up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "\n",
    "up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "\n",
    "up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "\n",
    "up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "conv10 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "\n",
    "conv11 = Conv2D(n_classes, (1, 1), activation='linear')(conv10)\n",
    "print(conv10.shape)\n",
    "out=conv11\n",
    "out = Lambda(lambda x: softmax(x, axis = 3))(conv11)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[out])\n",
    "\n",
    "keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)#learning rate optimisation\n",
    "# keras.optimizers.Adadelta(lr=learning_rate , rho=0.95, epsilon=None, decay=0.0)\n",
    "model.compile(optimizer = 'adam', loss = type_loss_function, metrics=['accuracy', recall, precision, fmeasure])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation parameters\n",
    "\n",
    "patch_arg = dict()\n",
    "mask_arg = dict()\n",
    "\n",
    "\n",
    "\n",
    "train_patch_generator = PatchBatchGeneratorAugCol(\n",
    "                                            **patch_arg,\n",
    "                                            directory = Train_path + '/Patches',\n",
    "                                            image_data_generator = ImageDataGenerator,\n",
    "                                            target_size = (patch_size, patch_size),                                  \n",
    "                                            color_mode = \"rgb\",\n",
    "                                            num_channels = 3,\n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode = None,\n",
    "                                            shuffle = True,\n",
    "                                            preprocessing_function_space = seq_det.augment_image,\n",
    "                                            preprocessing_function_colour = colour_augmentation_function,\n",
    "                                            seed = 1)\n",
    "    \n",
    "train_mask_generator = MasksBatchGeneratorAug(  \n",
    "                                            **mask_arg,\n",
    "                                            directory = Train_path + '/Masks',\n",
    "                                            image_data_generator = ImageDataGenerator,\n",
    "                                            target_size = (patch_size, patch_size),\n",
    "                                            num_channels = n_classes,\n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode = None,\n",
    "                                            shuffle = True,                                      \n",
    "                                            seed = 1,\n",
    "                                            preprocessing_function_space = seq_det.augment_image,\n",
    "                                            preprocessing_function = rgb_to_onehot_3cls)\n",
    "\n",
    "print('Train sets ready')\n",
    "\n",
    "train_patch_generator_copy = train_patch_generator\n",
    "train_mask_generator_copy = train_mask_generator\n",
    "\n",
    "train_generator = zip(train_patch_generator, train_mask_generator)\n",
    "\n",
    "# #Some check-ups\n",
    "# a= next(train_generator)\n",
    "# [a1,b1] = list(a) \n",
    "# (f, [ax0,ax1]) = plt.subplots(1, 2, figsize = (24, 6))\n",
    "# ax0.imshow(a1[1])\n",
    "# ax1.imshow(b1[1])\n",
    "# print (train_patch_generator.__getitem__(0).shape)\n",
    "# print (train_mask_generator.__getitem__(0).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_samples = len([name for name in os.listdir(Train_path + '/Patches/Group1/')])\n",
    "print (n_train_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_arg = dict()\n",
    "mask_arg = dict()\n",
    "\n",
    "val_patch_generator = PatchBatchGenerator(\n",
    "                                            directory = Val_path + '/Patches',\n",
    "                                            image_data_generator = ImageDataGenerator,\n",
    "                                            target_size = (patch_size, patch_size),\n",
    "                                            color_mode = \"rgb\",\n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode = None,\n",
    "                                            shuffle = False,\n",
    "                                            seed= 1)\n",
    "    \n",
    "val_mask_generator = MasksBatchGenerator(\n",
    "                                            directory = Val_path + '/Masks',\n",
    "                                            image_data_generator = ImageDataGenerator,\n",
    "                                            target_size = (patch_size, patch_size),\n",
    "                                            batch_size = batch_size,\n",
    "                                            num_channels = n_classes,\n",
    "                                            class_mode = None,\n",
    "                                            shuffle = False,\n",
    "                                            seed = 1,\n",
    "                                            preprocessing_function = rgb_to_onehot_3cls)\n",
    "\n",
    "print('Validation sets ready')\n",
    "validation_generator = zip(val_patch_generator, val_mask_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_validation_samples  = len([name for name in os.listdir(Val_path + '/Patches/Group1/')])\n",
    "print (n_validation_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight, history and model run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights Part 1\n",
    "\n",
    "if not os.path.exists(weights_path):\n",
    "        os.makedirs(weights_path)\n",
    "\n",
    "weights_file = weights_path + '/Weights_' + current_date + Exp +'_{epoch:02d}.h5'\n",
    "\n",
    "if not os.path.exists(weights_file):\n",
    "    with open(weights_file, 'w'): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(weights_file, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = patience, verbose = 1, mode = 'auto')\n",
    "#history = keras.callbacks.History()\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "                    train_generator,\n",
    "                    steps_per_epoch = n_train_samples/ batch_size,\n",
    "                    epochs = n_epoch,\n",
    "                    validation_data = validation_generator,\n",
    "                    shuffle = True,\n",
    "                    callbacks = [model_checkpoint, earlystop],\n",
    "                    validation_steps = n_validation_samples/batch_size,\n",
    "                    #     use_multiprocessing=True,\n",
    "                    #     workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights Part 2\n",
    "\n",
    "model.save_weights(weights_file)\n",
    "\n",
    "print(\"Weights saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# History\n",
    "\n",
    "if not os.path.exists(history_path):\n",
    "        os.makedirs(history_path)\n",
    "\n",
    "history_file = history_path + '/History_data_' + current_date + Exp +'.json'\n",
    "\n",
    "if not os.path.exists(history_file):\n",
    "    with open(history_file, 'w'): pass\n",
    "\n",
    "with open (history_file,'w') as file:\n",
    "    json.dump(history.history, file)\n",
    "    \n",
    "print(\"History saved\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "(f, [ax0, ax1, ax2, ax3]) = plt.subplots(1, 4, figsize = (24, 6))\n",
    "\n",
    "ax0.plot(history.history['loss'])\n",
    "ax0.plot(history.history['val_loss'])\n",
    "ax0.set_title('model loss')\n",
    "ax0.set_ylabel('loss')\n",
    "ax0.set_xlabel('epoch')\n",
    "ax0.legend(['train', 'valid'], loc = 'upper left')\n",
    "ax0.axis([0, n_epoch, 0, max(history.history['val_loss'])])\n",
    "\n",
    "ax1.plot(history.history['acc'])\n",
    "ax1.plot(history.history['val_acc'])\n",
    "ax1.set_title('model accuracy')\n",
    "ax1.set_ylabel('accuracy')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(['train', 'valid'], loc = 'upper left')\n",
    "ax1.axis([0, n_epoch, 0, 1])\n",
    "\n",
    "ax2.plot(history.history['recall'])\n",
    "ax2.plot(history.history['val_recall'])\n",
    "ax2.set_title('model recall')\n",
    "ax2.set_ylabel('recall')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(['train', 'valid'], loc = 'upper left')\n",
    "ax2.axis([0, n_epoch, 0, 1])\n",
    "\n",
    "ax3.plot(history.history['precision'])\n",
    "ax3.plot(history.history['val_precision'])\n",
    "ax3.set_title('model precision')\n",
    "ax3.set_ylabel('precision')\n",
    "ax3.set_xlabel('epoch')\n",
    "ax3.legend(['train', 'valid'], loc = 'upper left')\n",
    "ax3.axis([0, n_epoch, 0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
